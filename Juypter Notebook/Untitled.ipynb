{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd201322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ModelSelctor:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test,base_accuracy):\n",
    "        \n",
    "        try:\n",
    "            self.x_train = x_train,\n",
    "            self.y_train = y_train,\n",
    "            self.x_test = x_test,\n",
    "            self.y_test = y_test,\n",
    "            self.base_accuracy = base_accuracy\n",
    "\n",
    "            print(\"Model Selction Started\")\n",
    "        except Exception as e:\n",
    "            raise SalesException(e,sys) from e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_best_param_xgb(self):\n",
    "        try:\n",
    "            best_params={}\n",
    "\n",
    "            param1={'eta' : [i/100 for i in range(1,20)]}\n",
    "            param2={'max_depth' : range(3,10,1)}\n",
    "            param3={'gamma' : [i/10 for i in range(1,10)]}\n",
    "            param4={'subsample':[i/100.0 for i in range(70,100,5)]}\n",
    "            param5={'colsample_bytree':[i/100.0 for i in range(70,100,3)]}\n",
    "            param6={'alpha' : np.arange(0.1, 10, 0.1)}\n",
    "            param7={'n_estimators':range(10,100,5)}\n",
    "\n",
    "            parameters=[param1, param2, param3, param4, param5, param6, param7]\n",
    "\n",
    "            for param in parameters:\n",
    "                grid=GridSearchCV(XGBRegressor(objective='reg:squarederror'), param, cv=5, n_jobs=-1)\n",
    "                grid.fit(self.x_train, self.y_train)\n",
    "                best_params.update(grid.best_params_)\n",
    "\n",
    "            eta=best_params['eta']\n",
    "            max_depth=best_params['max_depth']\n",
    "            gamma=best_params['gamma']\n",
    "            subsample=best_params['subsample']\n",
    "            colsample_bytree=best_params['colsample_bytree']\n",
    "            alpha=best_params['eta']\n",
    "            n_estimators=best_params['n_estimators']\n",
    "\n",
    "            model=XGBRegressor(objective='reg:squarederror', eta=eta, max_depth=max_depth,  gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree, alpha=alpha, n_estimators=n_estimators)\n",
    "            model.fit(self.x_train, self.y_train)\n",
    "            y_pred=model.predict(self.x_test)\n",
    "\n",
    "            r2=r2_score(self.y_test, self.y_pred)\n",
    "            return model, r2\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def get_best_param_rf(self):\n",
    "        try:\n",
    "            best_params={}\n",
    "\n",
    "            param1={'criterion': ['squared_error', 'absolute_error']}\n",
    "            param2={'max_depth' : range(3,10,1)}\n",
    "            param3={'max_features' : [i/100.0 for i in range(70,100,3)]}\n",
    "            param4={'max_samples' : [i/100.0 for i in range(70,100,5)]}\n",
    "            param5={'n_estimators':range(10,100,5)}\n",
    "\n",
    "\n",
    "            parameters=[param1, param2, param3, param4, param5]\n",
    "\n",
    "            for param in parameters:\n",
    "                grid =GridSearchCV(RandomForestRegressor(), param, cv=5, n_jobs=-1)\n",
    "                grid.fit(self.x_train, self.y_train)\n",
    "                best_params.update(grid.best_params_)\n",
    "\n",
    "            criterion=best_params['criterion']\n",
    "            max_depth=best_params['max_depth']\n",
    "            max_features=best_params['max_features']\n",
    "            max_samples=best_params['max_samples']\n",
    "            n_estimators=best_params['n_estimators']\n",
    "\n",
    "\n",
    "\n",
    "            model=RandomForestRegressor(criterion=criterion, max_depth = max_depth, max_features = max_features, max_samples = max_samples, n_estimators = n_estimators)\n",
    "            model.fit(self.x_train, self.y_train)\n",
    "            y_pred=model.predict(self.x_test)\n",
    "\n",
    "            r2=r2_score(self.y_test, y_pred)\n",
    "            return model, r2\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def get_best_model(self):\n",
    "        xgb_model , xgb_r2 = self.get_best_param_xgb()\n",
    "        rf_model , rf_r2 = self.get_best_param_rf()\n",
    "\n",
    "        if xgb_r2 > self.base_accuracy and xgb_r2>rf_r2:\n",
    "            best_model,model_name = xgb_model ,'XGB'\n",
    "            print(f'best Model is {model_name} with parameters {best_model} ')\n",
    "        elif rf_r2 > self.base_accuracy and rf_r2>xgb_r2:\n",
    "            best_model,model_name = rf_model,'RandomForest'\n",
    "            print(f'best Model is {model_name} with parameters {best_model} ')\n",
    "        else:\n",
    "            print(f\"None of model has base accuracy more than {self.base_accuracy}\") \n",
    "\n",
    "        return best_model,model_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95574711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selction Started\n",
      "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=1.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8296\\3615519378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelSelctor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'model { model}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8296\\2908659611.py\u001b[0m in \u001b[0;36mget_best_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_best_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mxgb_model\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mxgb_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_param_xgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mrf_model\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrf_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_param_rf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv(r\"D:\\Projects_new\\Stores_Sales_Prediction\\sales\\artifact\\data_transformation\\2022-07-25-15-23-29\\preprocessed_files\\train_transformed\\train_array_df.csv\")\n",
    "\n",
    "x = train_df.drop(columns=['Item_Outlet_Sales'])\n",
    "y = train_df['Item_Outlet_Sales']\n",
    "x_train,  x_test,y_train, y_test = train_test_split(x,y,test_size=0.20)\n",
    "base_accuracy = 0.5 \n",
    "\n",
    "\n",
    "model = ModelSelctor(x_train=x_train,x_test=x_test,y_train=y_train,y_test=y_test,base_accuracy=0.4)\n",
    "\n",
    "model , model_name = model.get_best_model()\n",
    "\n",
    "print(f'model { model}')\n",
    "print(f'model_name {model_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a7a4e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4273    1640.5312\n",
       "1298    2406.2012\n",
       "5133     790.9704\n",
       "3638    1733.7432\n",
       "4453    3259.7568\n",
       "          ...    \n",
       "3260    1448.7808\n",
       "3248    2659.8710\n",
       "5284    1537.9980\n",
       "3820    2631.2416\n",
       "810     2972.7970\n",
       "Name: Item_Outlet_Sales, Length: 1364, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb08a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_param_rf(x_train, y_train, x_test, y_test):\n",
    "        try:\n",
    "            best_params={}\n",
    "\n",
    "            param1={'criterion': ['squared_error', 'absolute_error']}\n",
    "            param2={'max_depth' : range(3,10,1)}\n",
    "            param3={'max_features' : [i/100.0 for i in range(70,100,3)]}\n",
    "            param4={'max_samples' : [i/100.0 for i in range(70,100,5)]}\n",
    "            param5={'n_estimators':range(10,100,5)}\n",
    "\n",
    "\n",
    "            parameters=[param1, param2, param3, param4, param5]\n",
    "\n",
    "            for param in parameters:\n",
    "                grid =GridSearchCV(RandomForestRegressor(), param, cv=5, n_jobs=-1)\n",
    "                grid.fit(x_train, y_train)\n",
    "                best_params.update(grid.best_params_)\n",
    "\n",
    "            criterion=best_params['criterion']\n",
    "            max_depth=best_params['max_depth']\n",
    "            max_features=best_params['max_features']\n",
    "            max_samples=best_params['max_samples']\n",
    "            n_estimators=best_params['n_estimators']\n",
    "\n",
    "\n",
    "\n",
    "            model=RandomForestRegressor(criterion=criterion, max_depth = max_depth, max_features = max_features, max_samples = max_samples, n_estimators = n_estimators)\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred=model.predict(x_test)\n",
    "\n",
    "            r2=r2_score(y_test, y_pred)\n",
    "            return model, r2\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473d8618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'self' is not defined\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8296\\2031828708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_param_rf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    " model , r2 = get_best_param_rf(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c895d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
